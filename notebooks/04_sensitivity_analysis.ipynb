{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNkTW6CQnGu/F1q2RWwi8SH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Layer Sensitivity Analysis\n","\n","**Objective:**\n","Quantizing an entire neural network to 4-bit (INT4) often destroys accuracy. However, not all layers are equally important. This module implements a **Sensitivity Scanner** to identify which layers are \"Divas\" (fragile) and which are \"Stoics\" (robust).\n","\n","**The Strategy:**\n","We perform a \"perturbation test\" on the model:\n","1.  **Iterate** through every layer in the model.\n","2.  **Quantize** *only* that specific layer to INT4, keeping the rest of the model at FP32.\n","3.  **Measure** the damage (Drift) using KL Divergence compared to the baseline.\n","4.  **Policy:** Construct a Mixed-Precision configuration that keeps fragile layers at INT8 and compresses robust layers to INT4.\n","\n","**What to Expect (The \"Diva\" Pattern):**\n","While exact drift values will vary slightly due to the random calibration data, you should consistently observe three phenomena:\n","1.  **The Early Spike:** The first convolutional layers are often highly sensitive; corrupting raw features cascades errors through the whole network.\n","2.  **The Downsample Trap:** The 1x1 convolutions in Residual Shortcuts (e.g., `layerX.0.downsample.0`) are structural bottlenecks and usually show massive drift.\n","3.  **The Green Valley:** The majority of the deep 3x3 convolutions are incredibly robust and can be safely crushed to INT4.\n","\n","**Outcome:**\n","We expect to generate a policy that compresses the model to **~15% of its original size** (vs 25% for standard INT8) by proving that most layers do not need high precision."],"metadata":{"id":"NKcCZ04hPMpS"}},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"3tsZKDMEKjhr"},"outputs":[],"source":["# @title Setup & Calibration Data\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import copy\n","import numpy as np\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Running on: {device}\")\n","\n","# Load a standard backbone (ResNet18)\n","# We use this because it has a mix of 3x3 Convs, 1x1 Convs, and Downsampling layers\n","# which usually show distinct sensitivity patterns.\n","print(\"Loading ResNet18...\")\n","model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1).to(device)\n","model.eval()\n","\n","# Calibration Set\n","# In a real scenario, we'd grab a batch from the Val DataLoader.\n","# For this demo, we use synthetic data to ensure the code runs immediately without downloading ImageNet.\n","print(\"Generating Calibration Batch (N=128)...\")\n","calibration_data = torch.randn(128, 3, 224, 224).to(device)\n","\n","# Get \"Golden\" (FP32) Logits for baseline comparison\n","with torch.no_grad():\n","    golden_logits = model(calibration_data)\n","    golden_probs = F.softmax(golden_logits, dim=1)\n","\n","print(\"Baseline established.\")"]},{"cell_type":"code","source":["# @title Quantization Simulator (INT4)\n","def fake_quantize_tensor(tensor, num_bits=4):\n","    \"\"\"\n","    Simulates quantization noise on a weight tensor.\n","    Formula: Q = round(x / scale) * scale\n","    \"\"\"\n","    if num_bits >= 32:\n","        return tensor.clone()\n","\n","    # Calculate Dynamic Range\n","    qmin = -(2**(num_bits - 1))\n","    qmax = (2**(num_bits - 1)) - 1\n","    min_val, max_val = tensor.min(), tensor.max()\n","\n","    # Avoid div-by-zero if weight is all zeros (unlikely but possible in pruning)\n","    if min_val == max_val:\n","        return tensor.clone()\n","\n","    # Determine Scale\n","    scale = (max_val - min_val) / (qmax - qmin)\n","    zero_point = qmin - min_val / scale\n","\n","    # Simulate the hardware rounding\n","    q_tensor = (tensor / scale + zero_point).round().clamp(qmin, qmax)\n","    dq_tensor = (q_tensor - zero_point) * scale\n","\n","    return dq_tensor\n","\n","# Sanity Check (Always test your tools!)\n","print(\"--- Simulator Sanity Check ---\")\n","dummy = torch.tensor([-0.5, 0.0, 0.5, 1.2])\n","q_dummy = fake_quantize_tensor(dummy, num_bits=4)\n","print(f\"Input:    {dummy.numpy()}\")\n","print(f\"INT4 Sim: {q_dummy.numpy()}\")\n","print(\"Drift seems reasonable.\")"],"metadata":{"cellView":"form","id":"B4W-j9EVLlOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Metric: KL Divergence\n","def compute_kl_divergence(probs_p, probs_q):\n","    \"\"\"\n","    Calculates the Kullback-Leibler Divergence between two distributions.\n","    P: Golden (Target)\n","    Q: Quantized (Approximation)\n","    \"\"\"\n","    # Defensive coding: Add epsilon to prevent log(0) -> NaN\n","    epsilon = 1e-8\n","    probs_p = probs_p + epsilon\n","    probs_q = probs_q + epsilon\n","\n","    # KL(P || Q)\n","    # We sum across classes (dim=1) then mean across batch\n","    return torch.sum(probs_p * (probs_p / probs_q).log(), dim=1).mean().item()"],"metadata":{"cellView":"form","id":"IPesqt5tLnsC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Run Sensitivity Scan (Layer-by-Layer)\n","print(\"Starting Sensitivity Analysis...\")\n","print(\"Strategy: Quantize ONE layer to INT4, keep others FP32, measure KL Divergence.\")\n","\n","layer_sensitivities = {}\n","modules_to_scan = []\n","\n","# Filter for layers with weights\n","for name, module in model.named_modules():\n","    if isinstance(module, (nn.Conv2d, nn.Linear)):\n","        modules_to_scan.append((name, module))\n","\n","print(f\"Scanning {len(modules_to_scan)} layers. This may take a minute...\")\n","\n","for i, (name, module) in enumerate(modules_to_scan):\n","    # 1. Backup original weights\n","    original_weight = module.weight.data.clone()\n","\n","    # 2. Attack: Force this layer to INT4\n","    module.weight.data = fake_quantize_tensor(original_weight, num_bits=4)\n","\n","    # 3. Measure: Run inference and check drift\n","    with torch.no_grad():\n","        perturbed_logits = model(calibration_data)\n","        perturbed_probs = F.softmax(perturbed_logits, dim=1)\n","\n","    drift = compute_kl_divergence(golden_probs, perturbed_probs)\n","    layer_sensitivities[name] = drift\n","\n","    # 4. Restore: Reset weights for the next iteration\n","    module.weight.data = original_weight\n","\n","    # Progress log for the user\n","    if i % 5 == 0:\n","        print(f\"[{i}/{len(modules_to_scan)}] {name:<30} Drift: {drift:.5f}\")\n","\n","print(\"Scan Complete.\")"],"metadata":{"cellView":"form","id":"gEe6ps-xLpk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Visualization: The Sensitivity Heatmap\n","layers = list(layer_sensitivities.keys())\n","drifts = list(layer_sensitivities.values())\n","\n","# Dynamic thresholding for the chart\n","# We define \"Sensitive\" as anything > 1 standard deviation above the mean\n","threshold = np.mean(drifts) + np.std(drifts)\n","\n","colors = ['#2ecc71' if d < threshold else '#e74c3c' for d in drifts]\n","x = np.arange(len(layers))\n","\n","plt.figure(figsize=(14, 6))\n","bars = plt.bar(x, drifts, color=colors)\n","\n","# Add Threshold Line\n","plt.axhline(y=threshold, color='gray', linestyle='--', alpha=0.7, label='Sensitivity Threshold')\n","\n","# Aesthetics\n","plt.title('Layer Sensitivity Profile (ResNet18 @ INT4)')\n","plt.ylabel('KL Divergence (Drift)')\n","plt.xlabel('Layer Index (Input $\\\\rightarrow$ Output)')\n","plt.legend()\n","plt.grid(axis='y', alpha=0.2)\n","\n","# Auto-Annotate the \"Divas\" (Top 3 most sensitive)\n","sorted_indices = np.argsort(drifts)[::-1]\n","for i in range(3):\n","    idx = sorted_indices[i]\n","    plt.annotate(f\"{layers[idx]}\",\n","                 xy=(idx, drifts[idx]),\n","                 xytext=(idx, drifts[idx]*1.1),\n","                 ha='center', fontsize=8,\n","                 arrowprops=dict(arrowstyle=\"->\", color='black'))\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"cellView":"form","id":"x3vkCX9WLuYx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Automated Mixed-Precision Policy\n","# Generates a config dict based on the scan results\n","\n","print(\"--- Proposed Bit-Width Configuration ---\")\n","\n","policy = {}\n","savings_log = {\"INT8\": 0, \"INT4\": 0}\n","\n","for name, drift in layer_sensitivities.items():\n","    if drift > threshold:\n","        bitwidth = 8\n","        status = \"SENSITIVE\"\n","        savings_log[\"INT8\"] += 1\n","    else:\n","        bitwidth = 4\n","        status = \"ROBUST\"\n","        savings_log[\"INT4\"] += 1\n","\n","    policy[name] = bitwidth\n","\n","    # Print a few examples for verification\n","    if \"downsample\" in name or \"fc\" in name:\n","        print(f\"{name:<40} | Drift: {drift:.5f} | {status} -> {bitwidth}-bit\")\n","\n","# Summary\n","total_layers = len(policy)\n","avg_bits = (savings_log[\"INT8\"]*8 + savings_log[\"INT4\"]*4) / total_layers\n","print(\"-\" * 60)\n","print(f\"Final Policy: {savings_log['INT8']} Layers @ INT8, {savings_log['INT4']} Layers @ INT4\")\n","print(f\"Average Bit-Width: {avg_bits:.2f} bits (vs 32 bits FP32)\")\n","print(f\"Theoretical Model Size: {avg_bits/32*100:.1f}% of original\")"],"metadata":{"cellView":"form","id":"dn7_eWHmLx9I"},"execution_count":null,"outputs":[]}]}